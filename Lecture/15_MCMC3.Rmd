---
title: "MAT 653: Statistical Simulation"
author: Instructor$:$ Dr. Wei Li
date: "`r Sys.Date()`"
geometry: left=2cm, right=2cm, top=2cm, bottom=2cm
linestretch: 1.3
output:
  html_document:
    df_print: paged
    mathjax_config:
      - TeX-AMS-MML_HTMLorMML   
  pdf_document: 
      include:
        in_header: preamble_rmd.tex
  html_notebook: default
fontsize: 14pt
header-includes:
- \usepackage{amsmath}
- \usepackage[linewidth=1pt]{mdframed}
- \newcommand\inner[2]{\left\langle#1,#2\right\rangle}
- \newcommand\floor[1]{\lfloor#1\rfloor}
- \newcommand\ceil[1]{\lceil#1\rceil}
- \newcommand\mb[1]{\mathbf{#1}}
- \newcommand\bs[1]{\boldsymbol{#1}}
- \newcommand\mr[1]{\mathrm{#1}}
- \newcommand\wh[1]{\widehat{#1}}
- \newcommand\op[1]{\operatorname{#1}}
- \newcommand\mbb[1]{\mathbb{#1}}
- \usepackage{caption}
- \usepackage{mathtools}
- \captionsetup[figure]{labelformat=empty}
- \newcommand{\wei}[1]{\textcolor{orange}{(Wei:#1)}}
---


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>


<span style="background-color: #f5f5f5; padding: 5px; display: block;">
    <span style="width: 25%; display: inline-block; text-align: left;">
        [Back](javascript:window.history.back())
    </span>
    <span style="width: 30%; display: inline-block; text-align: center; color: grey;">
        **Updated:** `r Sys.Date()`
    </span>
    <span style="width: 35%; display: inline-block; text-align: right; color: grey;">
        Statistical Simulation, Wei Li
    </span>
</span>

<!------------->


## Metropolis-Hasting algorithm with different move types

We consider MH algorithms with different move types; which gives a more general framework for MH algorithms.

- $X \in \mathbb{R}^{d}$
- Let $M$ denote a finite or countable set of move types, e.g., $M=\{1, 2, \ldots, K\}$.
- $\gamma_m(x)$ denote probability of choosing move $m$ when the current value $X^{(s)}=x$, $\sum_{m} \gamma_m(x)=1$.

We first randomly choose a move type $m\in M$ and then generate $X^*$ with a move-dependent transition density $q_m(\cdot|X^{(s)})$, where $q_m(\cdot|\cdot): \mathbb{R}^d \times \mathbb{R}^d \to \mathbb{R}$. 

**MH algorithm with different move types**:

Let $s=0$.

1. Generate $m^{(s+1)}\in M$ with probability $P(m^{(s+1)}=m)=\gamma_m(X^{(s)})$;
2. Generate $X^* \sim q_{m^{(s+1)}}(\cdot|X^{(s)})$;
3. Let acceptance probablity be
$$
\alpha_{m^{(s+1)}}(X^{*}|X^{(s)})=\min \left\{ \frac{f(X^{*})\gamma_{m^{(s+1)}}(X^{*})q_{m^{(s+1)}}(X^{(s)}|X^{*})}{f(X^{(s)})\gamma_{m^{(s+1)}}(X^{(s)})q_{m^{(s+1)}}(X^{*}|X^{(s)})}, 1  \right\}
$$
4. Generate $U\sim \mbox{unif}(0,1)$
    i. if $U\leq \alpha_{m^{(s+1)}}(X^{*}|X^{(s)})$, set $X^{(s+1)} = X^*$;
    ii. if $U> \alpha_{m^{(s+1)}}(X^{*}|X^{(s)})$, set $X^{(s+1)} = X^{(s)}$.
5. $s\leftarrow s+1.$

**Remark**

(1) $\gamma_m(x)$ can depend on time as well. In the simplest case, for example, $M=\{1, 2,\ldots, K\}$, we can choose $m$ to be $(s \text{ mod } K)+1$, this will cylce through all move types.
(2) Every move type can be shown to satisfy detailed balance condition, but the composition needs not.
(3) Note that $q_m(\cdot|\cdot): \mathbb{R}^d \times \mathbb{R}^d \to \mathbb{R}$, this transition density may not be well-defined if we just want to update a single/part of the whole vector of $X \in \mathbb{R}^d$, so $X^*$ falls on a lower dimensional space of $X \in \mathbb{R}^d$.

**A modification**:

To address the above issue (3), we have a more general update rule for the acceptance probability. We need to assume two things for this.

1. Assume for *each* move $m\in M$, there is a set $C_m \subset \mathbb{R}^d \times \mathbb{R}^d$ such that
$$
(x, x') \in C_m \Longleftrightarrow  (x', x) \in C_m , \quad \forall x, x'
$$
2. and there is a density $\psi_m: C_m \to [0, \infty]$ such that the proposed $X^*$ transitioning from $X^{(s)} \sim f$ satisfies 
$$
P(X^*\in B, X^{(s)}\in A) =\int_{C_m} 1_A(x)1_B(x')\psi_m(x, x')dx'dx
$$
for all $A, B$.
The (modified) acceptance probability is 
$$
\alpha_m(X^*|X^{(s)})=\min \left\{  \frac{\gamma_m(X^{^*}) \psi_m(X^{*}, X^{(s)})}{\gamma_m(X^{(s)}) \psi_m(X^{(s)}, X^{*})}, 1 \right\}
$$

**Remark**:

(1) If the transition density $q_m$ from $X^{(s)}$ to $X^*$ exists (or well-defined density), then $\psi_m(x, x')=f(x)q_m(x'|x)$, giving the previous algorithm. More generally, however, in this modified algorithm, is that we allow $C_m$ to be a lower dimensional space of $\mathbb{R}^d \times \mathbb{R}^d$.
(2) This modified algorithm generalizes the blockwise MH algorithm and the Gibbs sampling. 


## Reversible Jump Markov Chain Monte Carlo


<!------------->
<span style="background-color: #f5f5f5; padding: 5px; display: block;">
    <span style="width: 25%; display: inline-block; text-align: left;">
        [Back](javascript:window.history.back())
    </span>
    <span style="width: 30%; display: inline-block; text-align: center; color: grey;">
        **Updated:** `r Sys.Date()`
    </span>
    <span style="width: 35%; display: inline-block; text-align: right; color: grey;">
        Statistical Simulation, Wei Li
    </span>
</span>
 